import React, { useState, useEffect, useRef } from 'react';

// Mock implementations for framer-motion components with enhanced functionality
const motion = {
  div: ({ 
    children, 
    initial, 
    animate, 
    exit, 
    whileHover, 
    whileTap, 
    style, 
    className, 
    ...props 
  }: any) => {
    // Extract animation props and apply them as appropriate
    return <div style={style} className={className} {...props}>{children}</div>;
  },
  button: ({ 
    children, 
    initial, 
    animate, 
    exit, 
    whileHover, 
    whileTap, 
    style, 
    className, 
    ...props 
  }: any) => {
    // Extract animation props and apply them as appropriate
    return <button style={style} className={className} {...props}>{children}</button>;
  }
};

const AnimatePresence = ({ children }: { children?: React.ReactNode }) => {
  return <>{children}</>;
};

// Enhanced error handling and logging
const logError = (message: string, error: any) => {
  console.error(`[VoiceCommandSystem Error] ${message}:`, error);
};

// Type definitions
interface VoiceCommandSystemProps {
  onNavigate: (route: AppRoute) => void;
  onAction?: (action: string, params?: any) => void;
}
import { Mic, MicOff, Volume2, Zap, Brain } from 'lucide-react';
import { AppRoute } from '../types';
import { soundSystem } from './SoundEffects';

const VoiceCommandSystem: React.FC<VoiceCommandSystemProps> = ({ onNavigate, onAction }) => {
  const [isListening, setIsListening] = useState(false);
  const [isActive, setIsActive] = useState(true);
  const [lastCommand, setLastCommand] = useState('');
  const [transcript, setTranscript] = useState('');
  const [feedback, setFeedback] = useState('');
  const [showFeedback, setShowFeedback] = useState(false);
  
  // AI-specific state
  const [aiStatus, setAiStatus] = useState('');
  const [predictionResult, setPredictionResult] = useState<any>(null);
  
  // Error tracking
  const [errorCount, setErrorCount] = useState(0);
  const [lastError, setLastError] = useState('');
  
  const recognitionRef = useRef<any>(null);
  const feedbackTimeoutRef = useRef<any>(null);

  // Initialize continuous speech recognition
  useEffect(() => {
    const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
    
    if (!SpeechRecognition) {
      console.error('‚ùå Speech recognition not supported in this browser');
      alert('Voice control requires Chrome, Edge, or Safari browser');
      setIsActive(false);
      return;
    }

    console.log('‚úÖ Speech Recognition API available');
    const recognition = new SpeechRecognition();
    recognition.continuous = false;  // Changed to false - no auto-restart
    recognition.interimResults = true;
    recognition.lang = 'en-US';
    
    recognition.onstart = () => {
      console.log('üé§ Voice recognition STARTED');
      setIsListening(true);
      showFeedbackMessage('üé§ Listening...');
    };

    recognition.onresult = (event: any) => {
      console.log('üìù Speech detected:', event);
      let interimTranscript = '';
      let finalTranscript = '';

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcript = event.results[i][0].transcript;
        if (event.results[i].isFinal) {
          finalTranscript += transcript;
        } else {
          interimTranscript += transcript;
        }
      }

      if (interimTranscript) {
        console.log('üí¨ Interim:', interimTranscript);
        setTranscript(interimTranscript);
      }

      if (finalTranscript) {
        console.log('‚úÖ Final transcript:', finalTranscript);
        setTranscript('');
        processVoiceCommand(finalTranscript.toLowerCase().trim());
      }
    };

    recognition.onerror = (event: any) => {
      console.error('‚ùå Speech recognition error:', event.error);
      
      if (event.error === 'not-allowed') {
        alert('‚ö†Ô∏è Microphone permission denied! Please allow microphone access in browser settings.');
        setIsActive(false);
        showFeedbackMessage('‚ùå Mic Permission Denied');
        return;
      }
      
      if (event.error === 'no-speech') {
        console.log('‚è∏ No speech detected');
        showFeedbackMessage('‚è∏ No speech detected - Click mic to try again');
        return;
      }
      
      if (event.error === 'aborted') {
        console.log('‚ö†Ô∏è Recognition aborted');
        return;
      }
    };

    recognition.onend = () => {
      console.log('‚èπ Voice recognition ended - Click mic button to speak again');
      setIsListening(false);
      showFeedbackMessage('‚úì Click mic button to speak again');
      // NO AUTO-RESTART - user must click button
    };

    recognitionRef.current = recognition;

    return () => {
      console.log('üõë Cleanup: Stopping voice recognition');
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
    };
  }, []);

  const speak = (text: string) => {
    window.speechSynthesis.cancel();
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.rate = 1.0;
    utterance.pitch = 1.0;
    utterance.volume = 1.0;
    window.speechSynthesis.speak(utterance);
  };

  const showFeedbackMessage = (message: string) => {
    setFeedback(message);
    setShowFeedback(true);
    
    if (feedbackTimeoutRef.current) {
      clearTimeout(feedbackTimeoutRef.current);
    }
    
    feedbackTimeoutRef.current = setTimeout(() => {
      setShowFeedback(false);
    }, 3000);
  };
  
  // Handle AI-specific commands
  const handleAICommand = async (command: string) => {
    setAiStatus('Processing AI command...');
    showFeedbackMessage('üß† Processing AI command...');
    
    try {
      if (command.includes('analyze') || command.includes('detect') || command.includes('predict')) {
        // Simulate AI analysis
        speak('Initiating brain scan analysis with AI model');
        
        // This would connect to your actual AI model
        onAction?.('start_analysis');
        
        // Simulate AI processing time
        setTimeout(() => {
          setAiStatus('Analysis complete');
          showFeedbackMessage('‚úì AI Analysis Complete');
          soundSystem.playSuccess();
        }, 2000);
        
        return;
      }
      
      if (command.includes('tumor') || command.includes('detection')) {
        speak('Running tumor detection algorithm');
        onAction?.('start_tumor_detection');
        
        setTimeout(() => {
          setAiStatus('Tumor detection complete');
          showFeedbackMessage('‚úì Tumor Detection Complete');
          
          // Simulated prediction result
          setPredictionResult({
            hasTumor: Math.random() > 0.5,
            confidence: Math.floor(Math.random() * 40) + 60, // 60-99%
            type: ['Glioma', 'Meningioma', 'Pituitary'][Math.floor(Math.random() * 3)],
            timestamp: new Date().toISOString()
          });
          
          soundSystem.playSuccess();
        }, 2500);
        
        return;
      }
      
      if (command.includes('error') || command.includes('debug')) {
        // Show error statistics
        speak(`Current error count is ${errorCount}. Last error was ${lastError}`);
        showFeedbackMessage(`Errors: ${errorCount}. Last: ${lastError.substring(0, 30)}...`);
        return;
      }
      
      // Default AI response
      speak('AI system ready for brain tumor analysis');
      showFeedbackMessage('üß† AI Ready');
      
    } catch (error) {
      console.error('Error in AI command:', error);
      logError('Error in AI command processing', error);
      setErrorCount(prev => prev + 1);
      setLastError(error instanceof Error ? error.message : String(error));
      setAiStatus('AI Error');
      showFeedbackMessage('‚ö†Ô∏è AI Processing Error');
      soundSystem.playError();
    }
  };

  const processVoiceCommand = (command: string) => {
    console.log('Processing command:', command);
    setLastCommand(command);
    soundSystem.playNotification();
    
    // Enhanced error tracking
    try {
      // Check for AI-related commands
      if (command.includes('ai') || command.includes('predict') || command.includes('analyze')) {
        handleAICommand(command);
        return;
      }
      
      // Process navigation commands
      if (command.includes('go to') || command.includes('open') || command.includes('show')) {
        if (command.includes('dashboard') || command.includes('home') || command.includes('main')) {
          onNavigate(AppRoute.DASHBOARD);
          speak('Opening Dashboard');
          showFeedbackMessage('‚úì Navigating to Dashboard');
          soundSystem.playSuccess();
          return;
        }
        
        if (command.includes('patient') || command.includes('registry')) {
          onNavigate(AppRoute.PATIENTS);
          speak('Opening Patient Registry');
          showFeedbackMessage('‚úì Navigating to Patients');
          soundSystem.playSuccess();
          return;
        }
        
        if (command.includes('scan') || command.includes('upload') || command.includes('diagnostic')) {
          onNavigate(AppRoute.SCAN);
          speak('Opening Diagnostic Engine');
          showFeedbackMessage('‚úì Navigating to Scan & Analyze');
          soundSystem.playSuccess();
          return;
        }
        
        if (command.includes('result') || command.includes('review')) {
          onNavigate(AppRoute.RESULTS);
          speak('Opening Review Center');
          showFeedbackMessage('‚úì Navigating to Results');
          soundSystem.playSuccess();
          return;
        }
        
        if (command.includes('knowledge') || command.includes('learn') || command.includes('info')) {
          onNavigate(AppRoute.KNOWLEDGE_BASE);
          speak('Opening Knowledge Base');
          showFeedbackMessage('‚úì Navigating to Knowledge Base');
          soundSystem.playSuccess();
          return;
        }
      }
      
      // Process action commands
      if (command.includes('download') || command.includes('save') || command.includes('export')) {
        if (command.includes('report') || command.includes('pdf')) {
          speak('Generating PDF report');
          showFeedbackMessage('‚úì Generating PDF Report...');
          soundSystem.playProcessing();
          onAction?.('download_report');
          return;
        }
      }
      
      if (command.includes('upload') || command.includes('select file') || command.includes('choose file')) {
        speak('Opening file selector');
        showFeedbackMessage('‚úì Opening file selector');
        onAction?.('open_file_selector');
        soundSystem.playClick();
        return;
      }
      
      if (command.includes('analyze') || command.includes('process') || command.includes('scan')) {
        speak('Starting AI Analysis');
        showFeedbackMessage('‚úì Starting AI Analysis...');
        soundSystem.playProcessing();
        onAction?.('start_analysis');
        return;
      }
      
      // Help command
      if (command.includes('help') || command.includes('what can you do') || command.includes('commands')) {
        const helpText = 'You can say: Go to Dashboard, Open Patients, Show Scan page, Go to Results, Order Medicine, Download Report, Upload Scan, or Analyze Image';
        speak(helpText);
        showFeedbackMessage('üí° Listening for commands...');
        return;
      }
      
      // Wake word detection
      if (command.includes('hey neuro') || command.includes('hi neuro') || command.includes('hello neuro')) {
        speak('Yes, I\'m listening. How can I help?');
        showFeedbackMessage('üëã Hello! I\'m ready');
        soundSystem.playNotification();
        return;
      }
      
      // If no command matched
      if (command.length > 3) {
        speak('I didn\'t understand that command. Say help for available commands.');
        showFeedbackMessage('‚ùì Command not recognized');
        soundSystem.playError();
      }
    } catch (error) {
      console.error('Error processing voice command:', error);
      logError('Error processing voice command', error);
      setErrorCount(prev => prev + 1);
      setLastError(error instanceof Error ? error.message : String(error));
      showFeedbackMessage('‚ö†Ô∏è Command processing error');
      soundSystem.playError();
    }

    // Navigation commands
    if (command.includes('go to') || command.includes('open') || command.includes('show')) {
      if (command.includes('dashboard') || command.includes('home') || command.includes('main')) {
        onNavigate(AppRoute.DASHBOARD);
        speak('Opening Dashboard');
        showFeedbackMessage('‚úì Navigating to Dashboard');
        soundSystem.playSuccess();
        return;
      }
      
      if (command.includes('patient') || command.includes('registry')) {
        onNavigate(AppRoute.PATIENTS);
        speak('Opening Patient Registry');
        showFeedbackMessage('‚úì Navigating to Patients');
        soundSystem.playSuccess();
        return;
      }
      
      if (command.includes('scan') || command.includes('upload') || command.includes('diagnostic')) {
        onNavigate(AppRoute.SCAN);
        speak('Opening Diagnostic Engine');
        showFeedbackMessage('‚úì Navigating to Scan & Analyze');
        soundSystem.playSuccess();
        return;
      }
      
      if (command.includes('result') || command.includes('review')) {
        onNavigate(AppRoute.RESULTS);
        speak('Opening Review Center');
        showFeedbackMessage('‚úì Navigating to Results');
        soundSystem.playSuccess();
        return;
      }
      
      if (command.includes('knowledge') || command.includes('learn') || command.includes('info')) {
        onNavigate(AppRoute.KNOWLEDGE_BASE);
        speak('Opening Knowledge Base');
        showFeedbackMessage('‚úì Navigating to Knowledge Base');
        soundSystem.playSuccess();
        return;
      }
      
      if (command.includes('medicine') || command.includes('order medicine') || command.includes('pharmacy') || command.includes('medication')) {
        onNavigate(AppRoute.MEDICINE_ORDER);
        speak('Opening Medicine Ordering System');
        showFeedbackMessage('‚úì Navigating to Medicine Order');
        soundSystem.playSuccess();
        return;
      }
    }

    // Action commands
    if (command.includes('download') || command.includes('save') || command.includes('export')) {
      if (command.includes('report') || command.includes('pdf')) {
        speak('Generating PDF report');
        showFeedbackMessage('‚úì Generating PDF Report...');
        soundSystem.playProcessing();
        onAction?.('download_report');
        return;
      }
    }

    if (command.includes('upload') || command.includes('select file') || command.includes('choose file')) {
      speak('Opening file selector');
      showFeedbackMessage('‚úì Opening file selector');
      onAction?.('open_file_selector');
      soundSystem.playClick();
      return;
    }

    if (command.includes('analyze') || command.includes('process') || command.includes('scan')) {
      speak('Starting analysis');
      showFeedbackMessage('‚úì Starting AI Analysis...');
      soundSystem.playProcessing();
      onAction?.('start_analysis');
      return;
    }

    // Help command
    if (command.includes('help') || command.includes('what can you do') || command.includes('commands')) {
      const helpText = 'You can say: Go to Dashboard, Open Patients, Show Scan page, Go to Results, Download Report, Upload Scan, or Analyze Image';
      speak(helpText);
      showFeedbackMessage('üí° Listening for commands...');
      return;
    }

    // Wake word detection
    if (command.includes('hey neuro') || command.includes('hi neuro') || command.includes('hello neuro')) {
      speak('Yes, I\'m listening. How can I help?');
      showFeedbackMessage('üëã Hello! I\'m ready');
      soundSystem.playNotification();
      return;
    }

    // If no command matched
    if (command.length > 3) {
      speak('I didn\'t understand that command. Say help for available commands.');
      showFeedbackMessage('‚ùì Command not recognized');
      soundSystem.playError();
    }
  };

  const toggleVoiceControl = () => {
    if (!recognitionRef.current) {
      console.error('‚ùå Recognition not initialized');
      return;
    }

    if (isListening) {
      // Stop listening
      console.log('üõë Stopping voice recognition manually...');
      recognitionRef.current.stop();
      setIsListening(false);
      showFeedbackMessage('‚èπ Voice stopped');
    } else {
      // Start listening
      try {
        console.log('üé§ STARTING voice recognition (manual click)...');
        recognitionRef.current.start();
        showFeedbackMessage('üé§ Listening - Speak now!');
        soundSystem.playNotification();
      } catch (e) {
        console.error('‚ùå Failed to start:', e);
        showFeedbackMessage('‚ùå Failed to start - Try again');
      }
    }
  };

  return (
    <>
      {/* Voice Control Toggle Button */}
      <motion.div
        initial={{ scale: 0 }}
        animate={{ scale: 1 }}
        className="fixed top-6 right-6 z-[1000] flex flex-col items-end gap-2"
      >
        {/* Feedback Display */}
        <AnimatePresence>
          {showFeedback && (
            <motion.div
              initial={{ opacity: 0, y: -10, x: 10 }}
              animate={{ opacity: 1, y: 0, x: 0 }}
              exit={{ opacity: 0, y: -10, x: 10 }}
              className="bg-gradient-to-r from-[#2A9D8F] to-[#4CC9F0] text-white px-6 py-3 rounded-2xl shadow-2xl font-bold text-sm flex items-center gap-2"
            >
              <Zap className="w-4 h-4" />
              {feedback}
            </motion.div>
          )}
        </AnimatePresence>

        {/* Transcript Display */}
        <AnimatePresence>
          {transcript && isListening && (
            <motion.div
              initial={{ opacity: 0, scale: 0.9 }}
              animate={{ opacity: 1, scale: 1 }}
              exit={{ opacity: 0, scale: 0.9 }}
              className="bg-white/95 backdrop-blur-xl border-2 border-[#4CC9F0] px-6 py-3 rounded-2xl shadow-xl max-w-md"
            >
              <div className="flex items-center gap-2 mb-1">
                <motion.div
                  animate={{ scale: [1, 1.2, 1] }}
                  transition={{ duration: 0.5, repeat: Infinity }}
                  className="w-2 h-2 bg-red-500 rounded-full"
                />
                <span className="text-xs font-black text-gray-500 uppercase tracking-wider">
                  Listening...
                </span>
              </div>
              <p className="text-[#0A2463] font-bold">{transcript}</p>
            </motion.div>
          )}
        </AnimatePresence>

        {/* Main Control Button */}
        <motion.button
          onClick={toggleVoiceControl}
          whileHover={{ scale: 1.05 }}
          whileTap={{ scale: 0.95 }}
          className={`relative w-16 h-16 rounded-2xl shadow-2xl flex items-center justify-center transition-all ${
            isActive
              ? 'bg-gradient-to-br from-[#2A9D8F] to-[#4CC9F0]'
              : 'bg-gray-400'
          }`}
        >
          {isActive && isListening && (
            <motion.div
              animate={{
                scale: [1, 1.4, 1],
                opacity: [0.5, 0.2, 0.5],
              }}
              transition={{ duration: 1.5, repeat: Infinity }}
              className="absolute inset-0 bg-[#4CC9F0] rounded-2xl"
            />
          )}
          
          <div className="relative z-10">
            {isActive ? (
              <Mic className="text-white w-7 h-7" strokeWidth={2.5} />
            ) : (
              <MicOff className="text-white w-7 h-7" strokeWidth={2.5} />
            )}
          </div>

          {/* Listening Indicator */}
          {isActive && isListening && (
            <motion.div
              animate={{
                scale: [1, 1.2, 1],
              }}
              transition={{ duration: 1, repeat: Infinity }}
              className="absolute -top-1 -right-1 w-4 h-4 bg-red-500 rounded-full border-2 border-white"
            />
          )}
        </motion.button>

        {/* Status Text */}
        <motion.div
          initial={{ opacity: 0 }}
          animate={{ opacity: 1 }}
          className="text-xs font-black text-white uppercase tracking-wider bg-[#0A2463]/80 backdrop-blur-md px-4 py-2 rounded-full"
        >
          {isActive ? (
            isListening ? 'üé§ Listening...' : '‚è∏ Paused'
          ) : (
            'üîá Voice Off'
          )}
        </motion.div>

        {/* Last Command */}
        {lastCommand && (
          <motion.div
            initial={{ opacity: 0 }}
            animate={{ opacity: 0.7 }}
            className="text-xs text-white/60 font-bold max-w-[200px] text-right bg-black/20 backdrop-blur-sm px-3 py-1 rounded-lg"
          >
            Last: "{lastCommand.substring(0, 30)}..."
          </motion.div>
        )}
        
        {/* AI Status */}
        {aiStatus && (
          <motion.div
            initial={{ opacity: 0 }}
            animate={{ opacity: 0.8 }}
            className="text-xs text-green-400 font-bold max-w-[200px] text-right bg-black/20 backdrop-blur-sm px-3 py-1 rounded-lg flex items-center gap-1"
          >
            <Brain className="w-3 h-3" />
            AI: {aiStatus}
          </motion.div>
        )}
        
        {/* Error Tracking */}
        {errorCount > 0 && (
          <motion.div
            initial={{ opacity: 0 }}
            animate={{ opacity: 0.8 }}
            className="text-xs text-red-400 font-bold max-w-[200px] text-right bg-black/20 backdrop-blur-sm px-3 py-1 rounded-lg flex items-center gap-1"
          >
            ‚ö†Ô∏è Errors: {errorCount}
          </motion.div>
        )}
      </motion.div>

      {/* Instructions Overlay (shows on first load) */}
      <AnimatePresence>
        {isActive && !lastCommand && (
          <motion.div
            initial={{ opacity: 0, y: 20 }}
            animate={{ opacity: 1, y: 0 }}
            exit={{ opacity: 0, y: -20 }}
            transition={{ delay: 1 }}
            className="fixed bottom-32 right-8 z-[999] max-w-sm"
          >
            <div className="bg-gradient-to-br from-[#0A2463] to-[#4361EE] text-white p-6 rounded-3xl shadow-2xl border-2 border-[#4CC9F0]/30">
              <div className="flex items-center gap-2 mb-3">
                <Volume2 className="w-5 h-5 text-[#4CC9F0]" />
                <h3 className="font-black text-lg">Voice Commands Active!</h3>
              </div>
              <p className="text-sm mb-3 text-white/80 leading-relaxed">
                Try saying:
              </p>
              <ul className="text-xs space-y-1 text-white/90 font-bold">
                <li>‚Ä¢ "Go to Dashboard"</li>
                <li>‚Ä¢ "Open Scan page"</li>
                <li>‚Ä¢ "Show Results"</li>
                <li>‚Ä¢ "Download Report"</li>
                <li>‚Ä¢ "Analyze Brain Scan"</li>
                <li>‚Ä¢ "Detect Tumor"</li>
                <li>‚Ä¢ "Order Medicine"</li>
                <li>‚Ä¢ "Show Errors"</li>
                <li>‚Ä¢ "Help" for more commands</li>
              </ul>
            </div>
          </motion.div>
        )}
      </AnimatePresence>
    </>
  );
};

export default VoiceCommandSystem;
